{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b82a8d-5b46-4d7b-8bcc-446b02aa758a",
   "metadata": {},
   "source": [
    "## 01.1 Memory Overallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6f4259-12af-4cb9-b8f7-860290374991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1,000,000 samples of 9 items each\n",
      "Data Comprehension size: 444.09 Mb\n",
      "Data List size: 396.09 Mb (1.12x smaller)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "def total_size(obj):\n",
    "    \"\"\"\n",
    "    Recursively calculates the total size of a Python object in memory,\n",
    "    including its contents.\n",
    "\n",
    "    Returns:\n",
    "        int: The total size of the object in bytes.\n",
    "    \"\"\"\n",
    "    children = 0\n",
    "    try:\n",
    "        children = sum(total_size(item) for item in obj)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return sys.getsizeof(obj) + children\n",
    "\n",
    "\n",
    "def sample_comp(a, b, N):\n",
    "    return [random.randint(a, b) for _ in range(N)]\n",
    "\n",
    "\n",
    "def sample_list(a, b, N):\n",
    "    return list([random.randint(a, b) for _ in range(N)])\n",
    "\n",
    "\n",
    "N_samples = 1_000_000\n",
    "sample_size = 9\n",
    "data_comp = [sample_comp(0, 100, sample_size) for _ in range(N_samples)]\n",
    "data_list = [sample_list(0, 100, sample_size) for _ in range(N_samples)]\n",
    "\n",
    "size_comp = max_size = total_size(data_comp) / 1e6\n",
    "size_list = total_size(data_list) / 1e6\n",
    "\n",
    "print(f\"Creating {N_samples:,d} samples of {sample_size} items each\")\n",
    "print(f\"Data Comprehension size: {size_comp:0.2f} Mb\")\n",
    "print(f\"Data List size: {size_list:0.2f} Mb ({max_size/size_list:0.2f}x smaller)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55ee87-413b-48ea-a267-50941cea659a",
   "metadata": {},
   "source": [
    "## 01.2 Using Tuples to Reduce Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6eff1e-2042-46e4-a28b-5d29d56b5d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Tuple size: 372.09 Mb (1.19x smaller)\n"
     ]
    }
   ],
   "source": [
    "def sample_tuple(a, b, N):\n",
    "    return tuple([random.randint(a, b) for _ in range(N)])\n",
    "\n",
    "data_tuple = [sample_tuple(0, 100, sample_size) for _ in range(N_samples)]\n",
    "size_tuple = total_size(data_tuple) / 1e6\n",
    "\n",
    "print(f\"Data Tuple size: {size_tuple:0.2f} Mb ({max_size/size_tuple:0.2f}x smaller)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e746816-9a9a-4e41-b1a0-cc10f81bf1c2",
   "metadata": {},
   "source": [
    "## 01.3 Memory Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb4741-460b-48f1-a147-ef5d2e99cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit l = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d062244-e614-4529-86b6-676849a2a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit t = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
