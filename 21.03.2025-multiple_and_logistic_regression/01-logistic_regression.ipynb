{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7415d1af-3f30-4166-9f72-7b2ec8a42f61",
   "metadata": {},
   "source": [
    "# Predicting Categories: Logistic Regression\n",
    "\n",
    "In previous chapters, we've seen how machine learning models can predict **continuous** variables—like the price of an apartment. However, in many cases, our goal is to predict a **category**, or a discrete value. Predicting categorical outcomes is known as **classification**, and there are various methods to achieve this.\n",
    "\n",
    "Here, we'll first introduce **logistic regression**, which shares conceptual similarities with linear regression. To understand why logistic regression is preferred, we'll initially attempt to solve a classification problem using linear regression and see why it's unsuitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e28c0-c74a-4ea3-878a-cbf0aa53e396",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Here we use a datasets where different types of movements were recorded, resulting in variables indicating acceleration and angular velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbc59c-6326-4ae2-898d-d61bf70fee80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e13e6d-4cfd-43c7-b116-c429b77e5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "movement = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/digital-sustainability/SAI3-2025/refs/heads/main/datasets/movement.csv\"\n",
    ")\n",
    "\n",
    "# Randomly sample 10 rows with a fixed seed of 5 for reproducibility\n",
    "movement.sample(10, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98c60a-4281-403d-af4d-4277f5de28dd",
   "metadata": {},
   "source": [
    "If we perform some exploratory data analysis, we find that the $z$-axis acceleration alone already provides a good distinction between the two types of movements. We'll use this feature as an illustrative example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0a639-e5c6-47d2-beda-d2cd83f08e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When we use `stat='density'`, the y-axis is normalized to show a (normalized) density instead of a count\n",
    "sns.histplot(data=movement, x='z_acc', hue='move_type', stat='density'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fda41-a1cf-4719-a0e7-b2df3553ad3c",
   "metadata": {},
   "source": [
    "Note that other features also differ somewhat between the two movement types but aren't as effective for binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3c2e1-c6c2-4a64-aa3d-3c26fe35f058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=movement, x='y_acc', hue='move_type', stat='density'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383aef3-13ba-45ad-b4d2-dbbd53c8e649",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Our goal now is to predict the `move_type` category using the `z_acc` feature. Let's plot this relationship first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64154760-a6c2-48ee-b33f-55d433f19f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=movement, x='z_acc', y='move_type');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f381a-eaf1-4b63-a2ca-a5d89f29f62c",
   "metadata": {},
   "source": [
    "We can approach this task using the method we've already learned — scikit-learn's `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca9c0e-0413-4f08-9595-bd146ffc52ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00134b02-2226-4b72-ae6e-8bfb7b56df01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lin_model = linear_model.LinearRegression()\n",
    "lin_model.fit(X=movement[['z_acc']].values, y=movement['move_type'])\n",
    "\n",
    "pred = lin_model.predict(np.arange(-10, 50, 1)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26f6e2-5a19-431d-bf7b-7d063ee38c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=movement, x='z_acc', y='move_type');\n",
    "plt.plot(np.arange(-10, 50, 1), pred, 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f95197-defc-4cc3-9397-bb9d4645a97a",
   "metadata": {},
   "source": [
    "Clearly, this linear regression model isn't appropriate for classification. While we could set a threshold at 0.5 (predicting class `0` below this value and class `1` above), there would still be significant issues. For instance, data points with extreme feature values disproportionately affect the predictions, leading to large errors.\n",
    "\n",
    "A more suitable approach is to pass the linear model's output through a **step function**. This step function is defined as follows:\n",
    "\n",
    "$$\n",
    "H(x, d) = \n",
    "\\begin{cases}\n",
    "0, & \\text{if } x < d \\\\\n",
    "1, & \\text{if } x > d\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Let's manually apply this function to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ec5f5-59e3-40ef-89d9-53176f82db06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def step(x, d):\n",
    "    out = np.zeros(len(x))\n",
    "    out[x>d] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b455ca-dc76-4336-ae47-14f9db4ac166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=movement, x='z_acc', y='move_type')\n",
    "\n",
    "# Plot a step function with a threshold of 9\n",
    "plt.plot(np.arange(-10, 50, 1), step(np.arange(-10, 50, 1), 9), 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371fdaac-2733-4957-9cee-450fc61ea407",
   "metadata": {},
   "source": [
    "Right now, we've manually set the threshold at 9. However, we'd prefer our model to automatically determine the optimal threshold. The problem with the step function above is that it's unsuitable for gradient descent, the optimization method we typically use.\n",
    "\n",
    "Gradient descent works by making small adjustments to parameters and checking whether these changes reduce the error. But with the step function, small adjustments to the parameter `d` usually don't change the outcome, because points rarely switch categories due to tiny parameter shifts. This creates a flat error landscape, leaving gradient descent unable to find a direction to reduce the error.\n",
    "\n",
    "Thus, we need a smoother function that's differentiable everywhere. A common choice is the **sigmoid** function, which closely resembles the step function but has smooth edges instead. The sigmoid is defined using two parameters: $w$, controlling steepness, and $d$, indicating its location:\n",
    "\n",
    "$$\n",
    "\\sigma(x; w, d) = \\frac{1}{1 + e^{-w(x - d)}}\n",
    "$$\n",
    "\n",
    "This smooth transition allows gradient descent to effectively optimize the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df309e-ad66-47e8-8a9d-495ee943e9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, d, w):\n",
    "    out = 1 / (1 + np.exp(-w*(x-d)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d186a43-6975-4329-9a9a-5bf3b22f7037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=movement, x='z_acc', y='move_type');\n",
    "\n",
    "# Plot a sigmoid function with a \"threshold\" of 9 and a steepness of 2\n",
    "plt.plot(np.arange(-10,50,0.1), sigmoid(np.arange(-10,50,0.1), 9, 2), 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852115f2",
   "metadata": {},
   "source": [
    "We now have a model that gives us smoother predictions. For instance, at an acceleration of `9`, the prediction is exactly $0.5$. This prediction can be interpreted as the **probability** of a point belonging to category `1`. Intuitively, points far to the right have a high probability of belonging to category `1`, while points far to the left are likely to belong to category `0`. A prediction around 0.5 indicates uncertainty.\n",
    "\n",
    "The difference between the prediction and the true value, such as $\\texttt{sigmoid}(x_i; w, d) - y_i$, isn't ideal for gradient descent, because even though the slope isn't zero, it's still very flat and makes optimization slow.\n",
    "\n",
    "Instead, we typically use a more effective metric for classification tasks: the **cross-entropy loss**, which provides steeper gradients, making optimization more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274900f-215f-4c3e-bab0-54b9b56b3ed9",
   "metadata": {},
   "source": [
    "## Logistic regression in scikit-learn\n",
    "\n",
    "Now that we understand why we can't use simple linear regression, let's have a look at how to do logistic regression in scikit-learn. Again we create the model and fit it with our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68f7a0-5c25-4fee-a3b9-2ecf7228bd31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_model = linear_model.LogisticRegression()\n",
    "log_model.fit(X=movement[['z_acc']].values, y=movement['move_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b8620-8666-4165-bc6d-be123ab13482",
   "metadata": {},
   "source": [
    "Once our model is trained, we can use it to make predictions in two ways:\n",
    "\n",
    "1. **Probabilities**: We can retrieve the probability of the sample belonging to category `0` or `1` (the output of the sigmoid function).\n",
    "2. **Predicted Category**: Alternatively, we can directly obtain the predicted class (0 or 1), usually by applying a threshold (often set at 0.5).\n",
    "\n",
    "Here's how we can get both outputs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa10602-2231-49b1-bb29-e87d5da07fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a range of z_acc values from -10 to 50 and format it as a matrix with one value per row\n",
    "z_acc_values = np.arange(-10, 50, 0.1).reshape(-1, 1)\n",
    "\n",
    "pred_prob = log_model.predict_proba(z_acc_values)\n",
    "pred = log_model.predict(z_acc_values)\n",
    "\n",
    "print(\"Shape of pred_prob:\", pred_prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2533ff",
   "metadata": {},
   "source": [
    "We observe that our prediction (`pred_proba`) returns an array with shape `(600, 2)`. Each of the 600 rows corresponds to one sample. The two columns represent probabilities for each class:\n",
    "\n",
    "- **Column 1** contains the probability that the sample belongs to category `0`.\n",
    "- **Column 2** gives the probability for the second category, corresponding to a `move_type` of `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660e468-89be-4b72-97fc-5ca43cfde667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data=movement, x='z_acc', y='move_type')\n",
    "\n",
    "# Plot the probability of the positive class (1)\n",
    "ax.plot(z_acc_values.flatten(), pred_prob[:, 1], 'r', label='P(move_type = 1)')\n",
    "\n",
    "# Plot the predicted class\n",
    "ax.plot(z_acc_values.flatten(), pred, 'g', label='Predicted Category')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d37a88-0a8f-4822-8a1a-d073ade91eac",
   "metadata": {},
   "source": [
    "## Estimating the Error\n",
    "\n",
    "We used **cross-entropy loss** during training, as it's a smooth, differentiable metric ideal for gradient descent optimization. However, cross-entropy values can be difficult to interpret intuitively.\n",
    "\n",
    "To better understand our model's accuracy, let's directly compare our predictions with the true labels. Below, we calculate the difference between the actual `move_type` and our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65972ba-febe-4e7b-9e0a-886f711cae2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_data = log_model.predict(movement[['z_acc']])\n",
    "\n",
    "movement['move_type'] - predict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3c4f1-17c9-47c5-8e3a-6cf28e5f8bc9",
   "metadata": {},
   "source": [
    "Whenever the difference is `0`, the prediction was accurate; whenever we see a `-1` or `1`, we've misclassified that data point. \n",
    "\n",
    "Let's first count how many predictions were incorrect. We'll use the absolute value to treat `-1` as a misclassification as well. Then we'll compute the misclassification rate as a percentage of all predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cae029-2075-419b-a919-22b8563537f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let the model predict the move_type based on the z_acc values\n",
    "predicted_move_types = log_model.predict(movement[['z_acc']].values)\n",
    "\n",
    "# The resulting array contains the difference between the actual move_type and the predicted move_type\n",
    "wrong_predictions = np.abs(movement['move_type'] - predicted_move_types)\n",
    "\n",
    "# Calculate the error rate by dividing the number of wrong predictions by the total number of samples\n",
    "error_rate = wrong_predictions.sum() / len(movement)\n",
    "\n",
    "# Print the error rate\n",
    "print(\"Error rate:\", error_rate)\n",
    "\n",
    "# Print the percentage of incorrect predictions\n",
    "print(f\"{error_rate:.2%} of the samples were classified incorrectly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7ac2c-8ab9-459f-b972-e7813b0c9709",
   "metadata": {},
   "source": [
    "And correctly classified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d458d-6025-4f9d-b4eb-158506f5eb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_correctly_predicted = np.sum((movement['move_type'] - predicted_move_types) == 0) / len(movement)\n",
    "print(f\"{num_correctly_predicted:.2%} of the samples were classified correctly.\")\n",
    "\n",
    "# Or easier:\n",
    "print(f\"{1 - error_rate:.2%} of the samples were classified correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fce08b-7eec-4791-a738-2941554391e6",
   "metadata": {},
   "source": [
    "So we have an accuracy of 86%. This seems quite good, but is it as good as it seems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c44609-231e-4308-b1b1-a66448575c1e",
   "metadata": {},
   "source": [
    "## Checking Model Quality\n",
    "\n",
    "Now, instead of calculating the overall accuracy, let's check how well our model performs for each category individually. In other words, we want to assess how accurately the model predicts each movement type separately.\n",
    "\n",
    "We can do this by selecting predictions corresponding to each category and then counting how many times the model predicted correctly for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf180608-1469-4221-a6a9-6a2d678e1a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Indicates whether the move type is 0 or not for each sample\n",
    "is_move_type_0 = movement['move_type'] == 0\n",
    "\n",
    "# Use the indicator array above to select only the samples where the (target) move type is 0 (let's call this the negative class)\n",
    "predictions_on_samples_with_actual_move_type_0 = predicted_move_types[is_move_type_0]\n",
    "\n",
    "# Count the number of samples where the prediction is 0 (true negatives)\n",
    "num_true_negatives = np.sum(predictions_on_samples_with_actual_move_type_0 == 0)\n",
    "\n",
    "print(\"Number of true negatives:\", num_true_negatives)\n",
    "\n",
    "# Or in one line:\n",
    "print(\"Number of true negatives:\", np.sum(predicted_move_types[movement['move_type'] == 0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aba2ce-a654-495a-9538-fe92e4697e91",
   "metadata": {},
   "source": [
    "or as a fraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2853f-ce48-40c9-929e-13099cd0a985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_negative_samples = is_move_type_0.sum()\n",
    "\n",
    "print(f\"True Negative Rate: {num_true_negatives / num_negative_samples:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c1b83-adb9-4a54-971d-4cdc2809e898",
   "metadata": {},
   "source": [
    "Here, we've correctly predicted the movement \"running\" (category 0) 95% of the time. Let's now examine how well our model's is able to detect the \"rotation\" (category 1) movement in comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39472ea-3ec4-434b-8d38-1969849306b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Indicates whether the move type is 1 or not for each sample\n",
    "is_move_type_1 = movement['move_type'] == 1\n",
    "\n",
    "# Let's call move_type = 1 the positive class\n",
    "actual_positives = movement[is_move_type_1]\n",
    "true_positives = predicted_move_types[(predicted_move_types == 1) & is_move_type_1]  # Predicted 1 and actual 1\n",
    "\n",
    "true_positive_rate = len(true_positives) / len(actual_positives)\n",
    "\n",
    "print(f\"True Positive Rate (Recall): {true_positive_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93a7dd-8a6e-479d-b58e-fa0f74e2a272",
   "metadata": {},
   "source": [
    "We see that our model correctly predicts only 48% of the \"rotation\" movements.\n",
    "\n",
    "Instead of manually calculating \"accuracy\" for each category, we can use scikit-learn's **confusion matrix**. This matrix conveniently summarizes how many predictions were correct or incorrect for each category. To use it, we simply provide the actual and predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412bc59-4f90-4e38-b10d-50f9ecce8cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02936ed2-ffaf-46d3-97c5-a1174e34c814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(movement[\"move_type\"], predicted_move_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252243c8-d855-47eb-8d80-208d056e6195",
   "metadata": {},
   "source": [
    "The confusion matrix displays the same results we calculated previously. The values `98` and `763` represent correctly classified movements, while `37` and `103` indicate misclassifications.\n",
    "\n",
    "Each entry in the confusion matrix has standard terminology. If we now define predicting **\"rotation\"** as the **positive** outcome and **\"running\"** as the **negative** outcome, we have:\n",
    "\n",
    "- Correctly classifying an actual **\"rotation\"** movement as **\"rotation\"** is a **True Positive (TP)**.\n",
    "- Incorrectly classifying a **\"rotation\"** movement as **\"running\"** is a **False Negative (FN)**.\n",
    "- Correctly classifying a **\"running\"** movement as **\"running\"** is a **True Negative (TN)**.\n",
    "- Incorrectly classifying a **\"running\"** movement as **\"rotation\"** is a **False Positive (FP)**.\n",
    "\n",
    "These four scenarios are summarized visually in the figure below:\n",
    "\n",
    "![Confusion Matrix](https://github.com/digital-sustainability/SAI3-2025/blob/main/illustrations/confusion_matrix.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea04f0c-82a1-466b-a57b-9fa62eae8f35",
   "metadata": {},
   "source": [
    "The accuracy (number of correctly predicted samples) we previously calculated can now easily be derived from the confusion matrix by summing the diagonal values (the correctly predicted outcomes) and dividing by the total number of data points:\n",
    "\n",
    "$$\n",
    "\\text{accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "In a later section, we'll introduce more sophisticated metrics based on combinations of these four terms. For now, let's focus on improving our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da7055-adca-4339-84bd-5920ec76e10e",
   "metadata": {},
   "source": [
    "## Imbalance\n",
    "\n",
    "Why does our model perform well on one type of movement but poorly on the other? The main reason is that the dataset is heavily **imbalanced**, meaning one category is significantly more common than the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84859e-c267-4cbd-b2f5-5b8b5a14c3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f'Number of \"running\": {len(movement[movement[\"move_type\"]==0])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4418c94-f376-4da5-8ab5-e894f0c0fdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f'Number of \"rotation\": {len(movement[movement[\"move_type\"]==1])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a020b85-b418-441f-9747-0cce0acb4d2b",
   "metadata": {},
   "source": [
    "Imagine if we had even fewer examples of the \"rotation\" movement — for instance, just two samples. In such a scenario, a naive model that **always** predicts \"running\" would achieve 99% accuracy effortlessly. This clearly isn't desirable!\n",
    "\n",
    "In situations like this, we need to explicitly inform our ML model to pay special attention to rare categories. We achieve this by assigning different **weights** to each category during the learning process.\n",
    "\n",
    "A common solution is to set these weights inversely proportional to the frequency of each category — e.g., `1/217` for one category and `1/63` for the other. For logistic regression in scikit-learn, this is done by providing a list of per-sample weights. We can easily achieve this by adding a weight column to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easier way to get the number of samples per class\n",
    "num_samples_per_class = movement[\"move_type\"].value_counts()\n",
    "num_samples_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469c7c9-6274-4549-a1a2-9e93ee35a1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the weights for each class\n",
    "weights = 1/num_samples_per_class\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9fd2b-fbc2-4628-9f84-53fb0778aad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create e new column called 'weight' and set it to 1 initially for all samples\n",
    "movement['weight'] = 1.0\n",
    "\n",
    "# Set the weight to the corresponding value for each class. Whenever you filter and set values in pandas at the same time, you should use .loc\n",
    "movement.loc[movement['move_type']==0, 'weight'] = weights[0]\n",
    "movement.loc[movement['move_type']==1, 'weight'] = weights[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e8de8-79a7-4adf-96b6-a0a08c957923",
   "metadata": {},
   "source": [
    "Let's tell our model to use these weights when fitting the parameters to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e09e9-580c-40df-814c-c7be983cec04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_model = linear_model.LogisticRegression()\n",
    "log_model.fit(X=movement[['z_acc']].values, y=movement['move_type'].values, sample_weight=movement['weight'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556352d7-0420-436b-9a08-dc9c955e59a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_prob = log_model.predict_proba(np.arange(-10,50,0.1)[:, np.newaxis])\n",
    "pred = log_model.predict(np.arange(-10,50,0.1)[:, np.newaxis])\n",
    "\n",
    "ax = sns.scatterplot(data=movement, x='z_acc', y='move_type')\n",
    "\n",
    "# Plot the probability of the positive class (1)\n",
    "ax.plot(z_acc_values.flatten(), pred_prob[:, 1], \"r\", label=\"P(move_type = 1)\")\n",
    "\n",
    "# Plot the predicted class\n",
    "ax.plot(z_acc_values.flatten(), pred, \"g\", label=\"Predicted Category\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afafe0c-8c48-4f43-81e5-dd49082aae27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_move_types = log_model.predict(movement[[\"z_acc\"]].values)\n",
    "\n",
    "confusion_matrix(movement[\"move_type\"], predicted_move_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa1d82-059f-4fab-81db-2851d2bf47e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actual_negatives = movement[movement[\"move_type\"] == 0]\n",
    "true_negatives = predicted_move_types[(predicted_move_types == 0) & (movement[\"move_type\"] == 0)]\n",
    "\n",
    "true_negative_rate = len(true_negatives) / len(actual_negatives)\n",
    "\n",
    "print(f\"True negative rate: {true_negative_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99009dc6-bc64-47d0-97e0-8840756d68b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actual_positives = movement[movement[\"move_type\"] == 1]\n",
    "true_positives = predicted_move_types[(predicted_move_types == 1) & (movement[\"move_type\"] == 1)]\n",
    "\n",
    "true_positive_rate = len(true_positives) / len(actual_positives)\n",
    "\n",
    "print(f\"True positive rate (Recall): {true_positive_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca943c-fafa-451e-b974-1fa92fa2daab",
   "metadata": {},
   "source": [
    "We observe that by using these sample weights, we significantly improved the model’s ability to correctly identify the positive (\"rotation\") cases, with only a minor reduction in correctly classifying negative (\"running\") cases.\n",
    "\n",
    "Assigning different weights is a common and effective practice across many machine learning methods, including deep learning. For example, when building a fraud-detection model, fraudulent transactions are usually very rare compared to legitimate ones. In such cases, assigning a higher weight to fraudulent examples ensures that the model pays greater attention to these rare — but crucial — instances during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10e2a2-6050-4a9b-b3aa-f6eb59963f4f",
   "metadata": {},
   "source": [
    "## Other Metrics\n",
    "\n",
    "Previously, we introduced the concepts of True/False Positives and Negatives (TP, FP, TN, FN) and used them to define evaluation metrics such as **accuracy**:\n",
    "\n",
    "$$\n",
    "\\text{accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "However, there are other important metrics commonly used in machine learning to evaluate model quality, notably **precision** and **recall**.\n",
    "\n",
    "- **Precision** measures how precise our predictions are: it tells us the proportion of predicted positives that are actually correct. Formally, it's defined as:\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "- **Recall** measures how effectively the model identifies positives: it tells us the fraction of actual positives that are correctly predicted. Formally:\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Ideally, we want both high precision and high recall. A high precision means our model rarely predicts positives incorrectly (low FP). However, precision alone doesn't guarantee good performance, because it ignores how many true positives we might have missed. Similarly, recall tells us if we're correctly identifying most positives, with few false negatives.\n",
    "\n",
    "Let's illustrate these concepts with a simple example, where we classify images as either \"cat\" or \"dog\". Let's see how good our model performs on detecting cats, i.e. we choose \"cat\" as the positive and \"dog\" as the negative class. We train two different models and obtain the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1662ed26",
   "metadata": {},
   "source": [
    "![Confusion Matrix for Cat/Dog Classification](https://raw.githubusercontent.com/digital-sustainability/SAI3-2025/refs/heads/main/illustrations/confusion_matrix_cat_dog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9fc6f9-a5d9-4fe9-a183-96958bdfee2b",
   "metadata": {},
   "source": [
    "We see in this example that both models (left and right) have the same **precision**:\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{5}{5 + 1} = 0.83\n",
    "$$\n",
    "\n",
    "This means that whenever our model predicts \"cat,\" it's usually correct, and we rarely misclassify dogs as cats (low false positives).\n",
    "\n",
    "However, let's consider the **recall**:\n",
    "\n",
    "- On the left side, we have:\n",
    "$$\n",
    "\\text{recall} = \\frac{5}{5 + 10} = 0.33\n",
    "$$\n",
    "This is poor—we're missing many actual cat images. Although our positive predictions (cats) are usually correct, we fail to identify most cats.\n",
    "\n",
    "- On the right side, the recall is much better:\n",
    "$$\n",
    "\\text{recall} = \\frac{5}{5 + 1} = 0.83\n",
    "$$\n",
    "Here, we're correctly identifying most of the cats.\n",
    "\n",
    "To combine precision and recall into a single metric, we commonly use the **F-score** (or F1-score), defined as the harmonic mean of precision and recall:\n",
    "\n",
    "$$\n",
    "F = 2 \\cdot \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "$$\n",
    "\n",
    "In our examples above, we get:\n",
    "- Left: $F = 0.47$ (poor)\n",
    "- Right: $F = 0.83$ (good)\n",
    "\n",
    "Depending on the problem, we might prioritize **precision** or **recall** differently.\n",
    "\n",
    "For example, imagine a system that detects **defective parts in a factory**. Ideally, we want both high precision and high recall:\n",
    "- High **recall** ensures we catch *all* defective parts — we don’t let bad products reach customers.\n",
    "- High **precision** ensures that when the system flags a part as defective, it *really is* defective — so we don’t waste time or money checking perfectly fine items.\n",
    "\n",
    "Now consider a **medical screening test**, such as one for detecting a serious disease. In this case, **high recall** becomes more important: we want to identify as many affected patients as possible, even if it means some healthy people get false positives. Missing someone who actually has the disease (a false negative) could have severe consequences.\n",
    "\n",
    "So depending on the context:\n",
    "- If **missing a positive case is costly or dangerous**, we prioritize **recall** (as in medical diagnostics).\n",
    "- If **raising a false alarm is costly or disruptive**, we prioritize **precision**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f1c3d-40e2-4f36-8025-eea160778882",
   "metadata": {},
   "source": [
    "## Metrics in scikit-learn\n",
    "\n",
    "We get access to all these metrics via scikit-learn. There are specific functions like ```precision_socre``` but we can also get a summary of all values with either ```precision_recall_fscore_support``` or ```classification_report```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f6caf-106a-4dce-9ab4-ac915df9789d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8db41-1cd6-416f-9974-8893956ceae8",
   "metadata": {},
   "source": [
    "First we redo our classification, once with and once without class weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d4b42-dc87-464d-a44d-507ff04a67c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_model_noweight = linear_model.LogisticRegression()\n",
    "log_model_noweight.fit(X=movement[['z_acc']], y=movement['move_type'])\n",
    "\n",
    "log_model_weight = linear_model.LogisticRegression()\n",
    "log_model_weight.fit(X=movement[['z_acc']], y=movement['move_type'], sample_weight=movement['weight']);\n",
    "\n",
    "predict_data_noweigth = log_model_noweight.predict(movement[['z_acc']])\n",
    "predict_data_weigth = log_model_weight.predict(movement[['z_acc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094ef01-015f-4406-8728-13f31f65d211",
   "metadata": {},
   "source": [
    "Now we compute can look at the reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ac6c6-bcf3-473d-a888-343bb62da20a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(movement['move_type'], predict_data_weigth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd819bf-d8d4-475e-86a3-09ef1c48c4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(movement['move_type'], predict_data_noweigth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63fa9d-96a7-4a60-951e-2d2c795494f4",
   "metadata": {},
   "source": [
    "We see that the model provides scores for each category. Depending on the task, we might be interested in evaluating individual categories or looking at overall performance.\n",
    "\n",
    "- In **binary classification** (e.g., sick vs. not sick), it's often enough to look at the metrics for one class (usually the positive class).\n",
    "- In **multi-class classification** (e.g., cats, dogs, rabbits), we typically want to assess performance across all categories.\n",
    "\n",
    "In such cases, we can use **average scores** such as the `f1-score`, which summarizes both precision and recall for each class. These scores can be averaged in different ways — for instance, the **macro average** treats all classes equally, while **weighted averages** give more importance to frequent classes.\n",
    "\n",
    "In the example above, we see that the **macro average F1-score improves when using class weights**, helping the model better handle imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731aa46-4b86-4d60-a64c-df1b3fb55a74",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35991a-e27c-4e58-8dbd-45adeb93e3b9",
   "metadata": {},
   "source": [
    "1. Import the `housing.csv` dataset from the dataset directory. The ```good_bad``` feature is an \"artifical\" binary feature indicating if the house is nice or not. **Note** that this is not exactly the same dataset as `kc_house_data.csv`!\n",
    "\n",
    "2. Use logistic regression to predict the ```good_bad``` feature with ```sqft_living```\n",
    "\n",
    "3. Find the accuracy of your model.\n",
    "\n",
    "4. Print a report of the scores of the classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAI3-2025-Dx0OIx0W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
